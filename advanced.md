Advanced / Practical Section
--
### Summary
For each of the three required data types (User, Post, and Comment), I have put together: 
* migration
* model (app/Models)
* factory
* repository representing the source api (app/Repositories/Api/Placeholder)
* importer class which consumes the repository and populates local db (app/Importers)
* artisan command to kick off the importer, possibly via a scheduled cron job
* api route for index action showing results from local db
* query object, which is the domain logic to load the data for the route (app/Queries)
* feature test (tests/Feature)

The additional requested show method for the User entity also exists.

### Design
The migrations, models, and factories are fairly straightforward and standard. Foreign key requirements in factories are generated by seeding a new instance of the foreign entity and returning the id. This is a great starting point, but something that frequently needs a smarter solution as reliance on an entity grows in the system and amount of residual seeded data scales up, slowing down the testing process significantly. 

The breakdown of routes into nested folders and sub files like this feels a bit over the top given the simple list of routes, however it's a good best practice to help keep things clean, organized, and easy to navigate as applications scale.

The repositories are fairly clean, and I'm generally happy with them. The specifics of the API endpoint which serves as the source of truth for this data is encapsulated within these classes, and nothing else needs to have knowledge of the API. Obvious next steps would be to add a show method to the interface and all three classes implementing it, and further functionality could be added as needed to support business needs.

The importer classes are sufficient, fairly clean, and accomplish their goals. Given more time, I would spend time looking for a cleaner way to abstract them. processRemoteDatum() was an obvious point of differentiation, but the abstraction is not intuitive. The logical differentiation is primarily in mapping the data, and a more meaningful method named based upon that would be easier to make sense of in future. The classes currently load full fk mappings from the database in order to ensure correct mappings, and this is a point of potential problem as things scale. This functionality can easily be pushed fully into sql via a subquery if we shift to using query builder.

The query objects represent getting the logic out of the controller. I believe the job of a controller method is to translate to and from http, and the remaining work should live elsewhere. 'Query' is a solution for that I picked up from my previous employer. They are paired with 'Commands' to house any write operation e.g. store, update, and delete. I'm certainly not hung up on these naming conventions or organization, but do like that the functionality lives in simple "plain old php" classes. 

The tests are extremely repetitive and perhaps poorly organized. Further, I have poor test coverage. This is the area most in need of attention and where I would aspire to spend time next.

### Database
The database has been designed to largely mirror what is seen at the data source.  

*_remote_id has been used to store a local copy of provided foreign keys within their system. 

A 'fetched_at' field has been added to denote the most recent programmatic update via api. There is no known scenario where this will differ from updated_at, but in most real-world cases it's a good idea to build a way to have that confidence from the start.

Indexes have been added as appropriate to try to be as search friendly as possible. They may need to be tweaked as specific features are built out and benchmarked. Depending on the amount of data the system sees, building an additional index via elasticsearch or similar technology might be a good idea.


### Notes
I'm using a prefix of 'placeholder' on entities to denote their representing data from the placeholder api instead of local. That is being dropped for the public facing api endpoints. This feels like something which needs a better name based upon context and business rules, and which would make sense to add to the urls.

All calls to the remote api are being logged in the api_logs table to provide an audit trail in the case of problems or confusion. 

### Going Forward

Regrouping on importers and fleshing out tests would be good next steps. Beyond that, find tuning for business needs and fleshing out to support more of the upstream data model would make good sense. Finally, the entire system could do with some load testing and optimization.
